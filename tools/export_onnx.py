import argparse
import os
import sys
import warnings
import torch
import torch.nn as nn
import numpy as np
from mmcv import Config
from mmcv.runner import load_checkpoint
from mmdet.models import build_detector

# 1. ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ path ä¸­
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ==============================================================================
# ğŸ’¡ Monkey Patch: ç¡®ä¿ DAF ç®—å­èƒ½è¢« ONNX å¯¼å‡º
# ==============================================================================
from projects.mmdet3d_plugin.ops import feature_maps_format

# (è¿™é‡Œä¿ç•™ä½ ç¯å¢ƒé‡Œå¯èƒ½éœ€è¦çš„ä»»ä½•è‡ªå®šä¹‰ Patch ä»£ç ï¼Œå¦‚æœä¹‹å‰æœ‰çš„è¯)

class SparseDriveONNXWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
        # æ˜¾å¼æå–ä¸¤ä¸ªä»»åŠ¡å¤´
        self.det_head = model.head.det_head
        self.map_head = model.head.map_head

    def forward(self, img, projection_mat, 
                prev_det_feat, prev_det_anchor, prev_det_conf, # [New] Det History
                prev_map_feat, prev_map_anchor, prev_map_conf, # [New] Map History
                instance_t_matrix, time_interval):             # [New] Ego Motion & DT
        
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½åœ¨åŒä¸€è®¾å¤‡
        dev = img.device
        projection_mat = projection_mat.to(dev)
        prev_det_feat = prev_det_feat.to(dev)
        prev_det_anchor = prev_det_anchor.to(dev)
        prev_det_conf = prev_det_conf.to(dev)
        prev_map_feat = prev_map_feat.to(dev)
        prev_map_anchor = prev_map_anchor.to(dev)
        prev_map_conf = prev_map_conf.to(dev)
        instance_t_matrix = instance_t_matrix.to(dev)
        time_interval = time_interval.to(dev)

        # 1. ç‰¹å¾æå– (å…±äº« Backbone å’Œ Neck)
        B, N, C, H, W = img.shape
        img_reshaped = img.reshape(B * N, C, H, W)
        x = self.model.img_backbone(img_reshaped)
        if self.model.img_neck is not None:
            x = self.model.img_neck(x)
            
        feature_maps = []
        for feat in x:
            _, C_feat, H_feat, W_feat = feat.shape
            feature_maps.append(feat.reshape(B, N, C_feat, H_feat, W_feat))
            
        # 2. æ ¼å¼åŒ–ç‰¹å¾å›¾ (è§¦å‘ DAF æ’ä»¶ä¼˜åŒ–)
        formatted_feature_maps = feature_maps_format(feature_maps)
        
        # æ„é€  Meta ä¿¡æ¯
        img_metas = [{'lidar2img': projection_mat[i], 'img_shape': [(H, W)] * N} for i in range(B)]
        image_wh = img.new_tensor([W, H]).view(1, 1, 2).repeat(B, N, 1)

        metas = {
            'img_metas': img_metas,
            'projection_mat': projection_mat, 
            'timestamp': 0, 
            'image_wh': image_wh 
        }

        # 3. æ¨ç†æ£€æµ‹å¤´ (Det Head)
        # [Update] ä¼ å…¥ time_interval å’Œ prev_confidence ä»¥å¯ç”¨ Z-Lock å’Œ Decay
        det_outs = self.det_head.forward_onnx(
            feature_maps=formatted_feature_maps,
            prev_instance_feature=prev_det_feat,
            prev_anchor=prev_det_anchor,
            instance_t_matrix=instance_t_matrix,
            time_interval=time_interval,
            prev_confidence=prev_det_conf,
            metas=metas 
        )

        # 4. æ¨ç†åœ°å›¾å¤´ (Map Head)
        # è™½ç„¶ Map å¯èƒ½ä¸ä½¿ç”¨ time_interval è¿›è¡Œä½ç§»è¡¥å¿ï¼Œä½† Decay é€»è¾‘å¯èƒ½éœ€è¦ prev_confidence
        # map_outs = self.map_head.forward_onnx(
        #     feature_maps=formatted_feature_maps,
        #     prev_instance_feature=prev_map_feat,
        #     prev_anchor=prev_map_anchor,
        #     instance_t_matrix=instance_t_matrix,
        #     time_interval=time_interval,
        #     prev_confidence=prev_map_conf,
        #     metas=metas 
        # )

        # 5. åˆå¹¶å¯¼å‡ºæ‰€æœ‰çš„è¾“å‡ºèŠ‚ç‚¹ (æ–°å¢äº† next_confidence)
        return (
            det_outs["cls_scores"], det_outs["bbox_preds"], 
            det_outs["next_instance_feature"], det_outs["next_anchor"], det_outs["next_confidence"],
            # map_outs["cls_scores"], map_outs["bbox_preds"],
            # map_outs["next_instance_feature"], map_outs["next_anchor"], map_outs["next_confidence"]
        )

def main():
    parser = argparse.ArgumentParser(description='Export SparseDrive Multi-Head to ONNX')
    parser.add_argument('--config', default="projects/configs/sparsedrive_small_stage2.py")
    parser.add_argument('--checkpoint', default='ckpt/sparsedrive_stage2.pth')
    parser.add_argument('--out', default='work_dirs/sparsedrive_small_stage2/sparsedrive_multihead.onnx')
    args = parser.parse_args()

    cfg = Config.fromfile(args.config)
    
    # å¼ºåˆ¶å¼€å¯æ£€æµ‹å’Œåœ°å›¾ä»»åŠ¡
    if hasattr(cfg, 'task_config'):
        print("âœ… Enabling Detection and Map tasks for export...")
        cfg.task_config['with_det'] = True
        cfg.task_config['with_map'] = True
        cfg.task_config['with_motion_plan'] = False
        if 'head' in cfg.model:
            cfg.model.head.task_config = cfg.task_config

    # åˆå§‹åŒ–æ¨¡å‹
    model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))
    load_checkpoint(model, args.checkpoint, map_location='cpu')
    model.cuda().eval()

    wrapper = SparseDriveONNXWrapper(model)
    
    # å‡†å¤‡ Dummy Inputs
    batch_size = 1
    num_cams = 6
    H, W = 256, 704 
    embed_dims = 256
    device = 'cuda'

    # è·å–å„è‡ªä»»åŠ¡çš„ History æ•°é‡
    num_det_history = model.head.det_head.instance_bank.num_temp_instances # 600
    num_map_history = model.head.map_head.instance_bank.num_temp_instances # 33
    
    dummy_img = torch.randn(batch_size, num_cams, 3, H, W, device=device)
    dummy_proj_mat = torch.randn(batch_size, num_cams, 4, 4, device=device)
    dummy_ego_mat = torch.eye(4, device=device).unsqueeze(0).repeat(batch_size, 1, 1)
    
    # [New] æ—¶é—´é—´éš”è¾“å…¥ (é€šå¸¸ä¸º 0.5s)
    dummy_time_interval = torch.tensor([0.5], dtype=torch.float32, device=device).repeat(batch_size)

    # æ£€æµ‹å¤´è¾“å…¥
    dummy_det_feat = torch.randn(batch_size, num_det_history, embed_dims, device=device)
    dummy_det_anchor = torch.randn(batch_size, num_det_history, 11, device=device)
    # [New] æ£€æµ‹å¤´ä¸Šä¸€å¸§ç½®ä¿¡åº¦ (èŒƒå›´ 0-1)
    dummy_det_conf = torch.rand(batch_size, num_det_history, device=device)

    # åœ°å›¾å¤´è¾“å…¥ (Map Anchor æ˜¯ 40 ç»´)
    dummy_map_feat = torch.randn(batch_size, num_map_history, embed_dims, device=device)
    dummy_map_anchor = torch.randn(batch_size, num_map_history, 40, device=device)
    # [New] åœ°å›¾å¤´ä¸Šä¸€å¸§ç½®ä¿¡åº¦
    dummy_map_conf = torch.rand(batch_size, num_map_history, device=device)

    input_names = [
        'img', 'projection_mat', 
        'prev_det_feat', 'prev_det_anchor', 'prev_det_conf',
        'prev_map_feat', 'prev_map_anchor', 'prev_map_conf',
        'instance_t_matrix', 'time_interval'
    ]
    
    output_names = [
        'det_cls', 'det_bbox', 'next_det_feat', 'next_det_anchor', 'next_det_conf',
        # 'map_cls', 'map_pts',  'next_map_feat', 'next_map_anchor', 'next_map_conf'
    ]

    print(f"ğŸš€ Exporting Multi-Head model to {args.out}...")
    with torch.no_grad():
        torch.onnx.export(
            wrapper,
            (dummy_img, dummy_proj_mat, 
             dummy_det_feat, dummy_det_anchor, dummy_det_conf,
             dummy_map_feat, dummy_map_anchor, dummy_map_conf,
             dummy_ego_mat, dummy_time_interval),
            args.out,
            input_names=input_names,
            output_names=output_names,
            opset_version=13,
            do_constant_folding=False,
        )
    
    print("ğŸ‰ Export finished successfully! Supported Inputs: Time Interval & History Confidence.")

if __name__ == '__main__':
    main()